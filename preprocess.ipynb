{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import re\n",
    "from gensim import models\n",
    "from scipy.sparse import lil_matrix\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "In this section, we preprocess the data and transform raw text data to matrix form. Then, all data is divided into training set and test set. After that, a dictionary is built upon training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_preprocess(doc):\n",
    "    return simple_preprocess(doc,min_len=1)\n",
    "\n",
    "def remove_specific_words(s):\n",
    "    s = re.sub(r\"\\bLyrics\\[.+\\]\",\" \",s)\n",
    "    s = re.sub(r\"\\[.+\\]\",\" \",s)\n",
    "    return s\n",
    "\n",
    "df = pd.read_csv(\"data/billboard_all_lyrics.csv\")\n",
    "\n",
    "df[\"lyrics\"] = df[\"lyrics\"].map(remove_specific_words)\n",
    "df[\"lyrics\"] = df[\"lyrics\"].map(remove_stopwords)\n",
    "df[\"lyrics\"] = df[\"lyrics\"].map(specific_preprocess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we should tag the data for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = np.zeros(len(df.iloc[:,0]))\n",
    "\n",
    "for i in range(len(df[\"label\"])):\n",
    "    if df.loc[i,\"year\"] < 1970:\n",
    "        df.loc[i,\"label\"] = 0\n",
    "    elif df.loc[i,\"year\"] <1980:\n",
    "        df.loc[i,\"label\"] = 1\n",
    "    elif df.loc[i,\"year\"] <1990:\n",
    "        df.loc[i,\"label\"] = 2\n",
    "    elif df.loc[i,\"year\"] <2000:\n",
    "        df.loc[i,\"label\"] = 3\n",
    "    elif df.loc[i,\"year\"] <2010:\n",
    "        df.loc[i,\"label\"] = 4\n",
    "    else:\n",
    "        df.loc[i,\"label\"] = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, data is split to training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(515)\n",
    "idx = np.repeat(range(10),len(df.iloc[:,0])//10+1)\n",
    "df[\"idx\"] = np.random.choice(idx[range(len(df.iloc[:,0]))],size=len(df.iloc[:,0]))\n",
    "df_train = df.loc[df[\"idx\"]!=0,:]\n",
    "df_test = df.loc[df[\"idx\"]==0,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dictionary based on training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_12736\\4121515207.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"freq_count\"] = [dictionary.doc2bow(text) for text in processed_corpus]\n"
     ]
    }
   ],
   "source": [
    "freq = defaultdict(int)\n",
    "for text in df_train[\"lyrics\"]:\n",
    "    for token in text:\n",
    "        freq[token] += 1\n",
    "\n",
    "processed_corpus = [[token for token in text if freq[token]>20] for text in df_train.loc[:,\"lyrics\"]]\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "df_train[\"freq_count\"] = [dictionary.doc2bow(text) for text in processed_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of columns from maximum word ID in the training data\n",
    "num_cols = max(dictionary.keys())+1\n",
    "dat_train = lil_matrix((len(df_train), num_cols), dtype=np.int64)\n",
    "\n",
    "# Fill in values using apply() and enumerate()\n",
    "def set_row_func(i, row):\n",
    "    indices = [count for count, word_id in row[\"freq_count\"]]\n",
    "    values = [value for _, value in row[\"freq_count\"]]\n",
    "    dat_train[i, indices] = values\n",
    "df_train[df_train[\"freq_count\"].map(len) > 0].reset_index(drop=True).reset_index().apply(lambda row: set_row_func(row[\"index\"], row), axis=1)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "dat_train = pd.DataFrame.sparse.from_spmatrix(dat_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, perform the same procedure to test set with the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_12736\\2217317512.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"freq_count\"] = [dictionary.doc2bow(text) for text in processed_corpus]\n"
     ]
    }
   ],
   "source": [
    "df_test = df.loc[df[\"idx\"]==0,:]\n",
    "processed_corpus = [[token for token in text if freq[token]>20] for text in df_test.loc[:,\"lyrics\"]]\n",
    "df_test[\"freq_count\"] = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "\n",
    "# Compute number of columns from maximum word ID in the training data\n",
    "num_cols = max(dictionary.keys())+1\n",
    "dat_test = lil_matrix((len(df_test), num_cols), dtype=np.int64)\n",
    "\n",
    "# Fill in values using apply() and enumerate()\n",
    "def set_row_func(i, row):\n",
    "    indices = [count for count, word_id in row[\"freq_count\"] if count < num_cols]\n",
    "    values = [value for count, value in row[\"freq_count\"] if count < num_cols and value!=0]\n",
    "    dat_test[i, indices] = values\n",
    "df_test[df_test[\"freq_count\"].map(len) > 0].reset_index(drop=True).reset_index().apply(lambda row: set_row_func(row[\"index\"], row), axis=1)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "dat_test = pd.DataFrame.sparse.from_spmatrix(dat_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_12736\\1318062561.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"tfidf\"]=tfidf[df_train[\"lyrics\"].map(dictionary.doc2bow)]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = list(df_train[\"freq_count\"])\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "df_train[\"tfidf\"]=tfidf[df_train[\"lyrics\"].map(dictionary.doc2bow)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of columns from maximum word ID in the training data\n",
    "num_cols = max(dictionary.keys())+1\n",
    "dat_tfidf_train = lil_matrix((len(df_train), num_cols), dtype=np.int64)\n",
    "\n",
    "# Fill in values using apply() and enumerate()\n",
    "def set_row_func(i, row):\n",
    "    indices = [count for count, word_id in row[\"tfidf\"]]\n",
    "    values = [value for _, value in row[\"tfidf\"]]\n",
    "    dat_tfidf_train[i, indices] = values\n",
    "df_train[df_train[\"tfidf\"].map(len) > 0].reset_index(drop=True).reset_index().apply(lambda row: set_row_func(row[\"index\"], row), axis=1)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "dat_tfidf_train = pd.DataFrame.sparse.from_spmatrix(dat_tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_12736\\2525057283.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"tfidf\"]=tfidf[df_test[\"lyrics\"].map(dictionary.doc2bow)]\n"
     ]
    }
   ],
   "source": [
    "df_test[\"tfidf\"]=tfidf[df_test[\"lyrics\"].map(dictionary.doc2bow)]\n",
    "\n",
    "# Compute number of columns from maximum word ID in the training data\n",
    "num_cols = max(dictionary.keys())+1\n",
    "dat_tfidf_test = lil_matrix((len(df_test), num_cols), dtype=np.int64)\n",
    "\n",
    "# Fill in values using apply() and enumerate()\n",
    "def set_row_func(i, row):\n",
    "    indices = [count for count, word_id in row[\"tfidf\"] if count < num_cols]\n",
    "    values = [value for count, value in row[\"tfidf\"] if count < num_cols and value != 0]\n",
    "    dat_tfidf_test[i, indices] = values\n",
    "df_test[df_test[\"tfidf\"].map(len) > 0].reset_index(drop=True).reset_index().apply(lambda row: set_row_func(row[\"index\"], row), axis=1)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "dat_tfidf_test = pd.DataFrame.sparse.from_spmatrix(dat_tfidf_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform word embedding\n",
    "Word embedding are used based on word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "wv = api.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
       "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
       "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
       "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
       "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
       "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
       "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
       "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
       "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
       "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
       "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
       "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
       "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
       "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
       "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
       "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
       "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
       "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
       "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
       "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
       "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
       "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
       "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
       "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
       "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
       "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
       "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
       "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
       "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
       "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
       "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
       "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
       "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
       "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
       "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
       "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
       "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
       "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
       "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
       "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
       "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
       "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
       "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
       "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
       "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
       "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
       "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
       "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
       "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
       "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
       "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
       "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
       "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
       "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
       "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
       "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
       "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
       "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
       "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
       "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
       "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
       "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
       "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
       "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
       "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
       "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
       "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
       "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
       "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
       "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
       "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
       "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
       "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
       "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
       "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv['king']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
