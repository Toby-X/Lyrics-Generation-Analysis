{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import re\n",
    "from gensim import models\n",
    "from scipy.sparse import lil_matrix, hstack, csr_matrix, vstack\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "In this section, we preprocess the data and transform raw text data to matrix form. Then, all data is divided into training set and test set. After that, a dictionary is built upon training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_preprocess(doc):\n",
    "    return simple_preprocess(doc,min_len=1)\n",
    "\n",
    "def remove_specific_words(s):\n",
    "    s = re.sub(r\"\\bLyrics\\[.+\\]\",\" \",s)\n",
    "    s = re.sub(r\"\\[.+\\]\",\" \",s)\n",
    "    return s\n",
    "\n",
    "df = pd.read_csv(\"data/billboard_lyrics_genres.csv\")\n",
    "\n",
    "df[\"lyrics\"] = df[\"lyrics\"].map(remove_specific_words)\n",
    "df[\"lyrics\"] = df[\"lyrics\"].map(remove_stopwords)\n",
    "df[\"lyrics\"] = df[\"lyrics\"].map(specific_preprocess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then delete the songs that are not English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(w):\n",
    "    return w.encode(\"utf-8\").isalpha()\n",
    "\n",
    "def isListEnglish(L):\n",
    "    return all(map(isEnglish,L))\n",
    "\n",
    "df[\"isEnglish\"] = df[\"lyrics\"].map(isListEnglish)\n",
    "df = df.loc[df[\"isEnglish\"],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, perform the same procedure to genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(s):\n",
    "    s = re.sub(r\"\\[\\'\",\" \",s)\n",
    "    s = re.sub(r\"\\'\\]\",\" \",s)\n",
    "    s = re.sub(r\"\\'\",\" \",s)\n",
    "    s = re.sub(r\"\\[\\]\",\" \",s)\n",
    "    s = re.sub(r\"\\,\",\" \",s)\n",
    "    s = s.split()\n",
    "    s = [token.lower() for token in s]\n",
    "    return s\n",
    "\n",
    "\n",
    "df[\"genre\"] = df[\"genre\"].map(remove_pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': 146,\n",
      " 'and': 157,\n",
      " 'country': 416,\n",
      " 'dance-pop': 155,\n",
      " 'disco': 147,\n",
      " 'folk': 141,\n",
      " 'funk': 170,\n",
      " 'hard': 102,\n",
      " 'hip': 432,\n",
      " 'hop': 374,\n",
      " 'new': 168,\n",
      " 'pop': 1381,\n",
      " 'r&b': 665,\n",
      " 'rap': 114,\n",
      " 'rock': 1606,\n",
      " 'roll': 111,\n",
      " 'soft': 322,\n",
      " 'soul': 476,\n",
      " 'wave': 109}\n"
     ]
    }
   ],
   "source": [
    "freq_gen = defaultdict(int)\n",
    "for text in df[\"genre\"]:\n",
    "    for token in text:\n",
    "        freq_gen[token] += 1\n",
    "\n",
    "processed_corpus_gen = [[token for token in text if freq_gen[token]>20] for text in df.loc[:,\"genre\"]]\n",
    "dict_gen = corpora.Dictionary(processed_corpus_gen)\n",
    "freq_wanted = {k: v for k,v in freq_gen.items() if v > 100}\n",
    "pprint.pprint(freq_wanted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, we can sort out the genre we want is alternative, country, dance, disco, folk, funk, hip-hop, new wave, pop, r&b, rap, rock, soul (soft stands for soft rock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_des = [\"alternative\",\"country\",\"dance\",\"disco\",\"folk\",\"funk\",\"hip\",\"new\",\"pop\",\"r&b\",\"rap\",\"rock\",\"soul\"]\n",
    "gen_des = sorted(gen_des)\n",
    "\n",
    "# Compute number of columns from maximum word ID in the training data\n",
    "num_cols = len(gen_des)\n",
    "dat_gen = lil_matrix((len(df), num_cols), dtype=np.int64)\n",
    "\n",
    "# Fill in values using apply() and enumerate()\n",
    "def set_row_func(i, row):\n",
    "    for word in row[\"genre\"]:\n",
    "        for k in range(len(gen_des)):\n",
    "            if re.search(gen_des[k],word):\n",
    "                dat_gen[i,k] = 1\n",
    "df[df[\"genre\"].map(len) > 0].reset_index(drop=True).reset_index().apply(lambda row: set_row_func(row[\"index\"], row), axis=1)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "dat_gen = pd.DataFrame.sparse.from_spmatrix(dat_gen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we should tag the data for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = np.zeros(df.shape[0])\n",
    "\n",
    "bins = [1970,1980,1990,2000,2010,np.inf]\n",
    "\n",
    "labels = [0,1,2,3,4,5]\n",
    "\n",
    "df[\"label\"] = np.where(df[\"year\"] < bins[0], labels[0],\n",
    "                               np.where(df[\"year\"] < bins[1], labels[1],\n",
    "                                        np.where(df[\"year\"] < bins[2], labels[2],\n",
    "                                                 np.where(df[\"year\"] < bins[3], labels[3],\n",
    "                                                          np.where(df[\"year\"] < bins[4], labels[4], labels[5])))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, data is split to training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(515)\n",
    "idx = np.repeat(range(10),len(df.iloc[:,0])//10+1)\n",
    "df[\"idx\"] = np.random.choice(idx[range(len(df.iloc[:,0]))],size=len(df.iloc[:,0]))\n",
    "df_train = df.loc[df[\"idx\"]!=0,:]\n",
    "df_test = df.loc[df[\"idx\"]==0,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dictionary based on training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_18576\\4121515207.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"freq_count\"] = [dictionary.doc2bow(text) for text in processed_corpus]\n"
     ]
    }
   ],
   "source": [
    "freq = defaultdict(int)\n",
    "for text in df_train[\"lyrics\"]:\n",
    "    for token in text:\n",
    "        freq[token] += 1\n",
    "\n",
    "processed_corpus = [[token for token in text if freq[token]>20] for text in df_train.loc[:,\"lyrics\"]]\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "df_train[\"freq_count\"] = [dictionary.doc2bow(text) for text in processed_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of columns from maximum word ID in the training data\n",
    "num_cols = max(dictionary.keys())+1\n",
    "dat_train = lil_matrix((len(df_train), num_cols), dtype=np.int64)\n",
    "\n",
    "# Fill in values using apply() and enumerate()\n",
    "def set_row_func(i, row):\n",
    "    indices = [count for count, word_id in row[\"freq_count\"]]\n",
    "    values = [value for _, value in row[\"freq_count\"]]\n",
    "    dat_train[i, indices] = values\n",
    "df_train[df_train[\"freq_count\"].map(len) > 0].reset_index(drop=True).reset_index().apply(lambda row: set_row_func(row[\"index\"], row), axis=1)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "dat_train = pd.DataFrame.sparse.from_spmatrix(dat_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, perform the same procedure to test set with the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_18576\\2217317512.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"freq_count\"] = [dictionary.doc2bow(text) for text in processed_corpus]\n"
     ]
    }
   ],
   "source": [
    "df_test = df.loc[df[\"idx\"]==0,:]\n",
    "processed_corpus = [[token for token in text if freq[token]>20] for text in df_test.loc[:,\"lyrics\"]]\n",
    "df_test[\"freq_count\"] = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "\n",
    "# Compute number of columns from maximum word ID in the training data\n",
    "num_cols = max(dictionary.keys())+1\n",
    "dat_test = lil_matrix((len(df_test), num_cols), dtype=np.int64)\n",
    "\n",
    "# Fill in values using apply() and enumerate()\n",
    "def set_row_func(i, row):\n",
    "    indices = [count for count, word_id in row[\"freq_count\"] if count < num_cols]\n",
    "    values = [value for count, value in row[\"freq_count\"] if count < num_cols and value!=0]\n",
    "    dat_test[i, indices] = values\n",
    "df_test[df_test[\"freq_count\"].map(len) > 0].reset_index(drop=True).reset_index().apply(lambda row: set_row_func(row[\"index\"], row), axis=1)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "dat_test = pd.DataFrame.sparse.from_spmatrix(dat_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_18576\\1318062561.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"tfidf\"]=tfidf[df_train[\"lyrics\"].map(dictionary.doc2bow)]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = list(df_train[\"freq_count\"])\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "df_train[\"tfidf\"]=tfidf[df_train[\"lyrics\"].map(dictionary.doc2bow)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of columns from maximum word ID in the training data\n",
    "num_cols = max(dictionary.keys())+1\n",
    "dat_tfidf_train = lil_matrix((len(df_train), num_cols), dtype=np.float64)\n",
    "\n",
    "# Fill in values using apply() and enumerate()\n",
    "def set_row_func(i, row):\n",
    "    indices = [count for count, word_id in row[\"tfidf\"]]\n",
    "    values = [value for _, value in row[\"tfidf\"]]\n",
    "    dat_tfidf_train[i, indices] = values\n",
    "df_train[df_train[\"tfidf\"].map(len) > 0].reset_index(drop=True).reset_index().apply(lambda row: set_row_func(row[\"index\"], row), axis=1)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "dat_tfidf_train = pd.DataFrame.sparse.from_spmatrix(dat_tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_18576\\3654324900.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"tfidf\"]=tfidf[df_test[\"lyrics\"].map(dictionary.doc2bow)]\n"
     ]
    }
   ],
   "source": [
    "df_test[\"tfidf\"]=tfidf[df_test[\"lyrics\"].map(dictionary.doc2bow)]\n",
    "\n",
    "# Compute number of columns from maximum word ID in the training data\n",
    "num_cols = max(dictionary.keys())+1\n",
    "dat_tfidf_test = lil_matrix((len(df_test), num_cols), dtype=np.float64)\n",
    "\n",
    "# Fill in values using apply() and enumerate()\n",
    "def set_row_func(i, row):\n",
    "    indices = [count for count, word_id in row[\"tfidf\"] if count < num_cols]\n",
    "    values = [value for count, value in row[\"tfidf\"] if count < num_cols and value != 0]\n",
    "    dat_tfidf_test[i, indices] = values\n",
    "df_test[df_test[\"tfidf\"].map(len) > 0].reset_index(drop=True).reset_index().apply(lambda row: set_row_func(row[\"index\"], row), axis=1)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "dat_tfidf_test = pd.DataFrame.sparse.from_spmatrix(dat_tfidf_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed Data\n",
    "The data processed are diveded into the blow categories:\n",
    "\n",
    "Original word frequency + genre\n",
    "\n",
    "TF-IDF word frequency + genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_gen = dat_gen.reset_index()\n",
    "df = df.reset_index(drop=True)\n",
    "dat_gen_train = dat_gen.loc[df[\"idx\"]!=0,:].reset_index(drop=True)\n",
    "dat_gen_test = dat_gen.loc[df[\"idx\"]==0,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = csr_matrix(df_train.loc[:,\"label\"]).transpose()\n",
    "test_label = csr_matrix(df_test.loc[:,\"label\"]).transpose()\n",
    "\n",
    "gen_train = csr_matrix(dat_gen_train.loc[:,0:])\n",
    "lyrics_train = csr_matrix(dat_train.loc[:,0:])\n",
    "data_train = hstack([gen_train, lyrics_train,train_label])\n",
    "data_train = pd.DataFrame.sparse.from_spmatrix(data_train)\n",
    "\n",
    "gen_test = csr_matrix(dat_gen_test.loc[:,0:])\n",
    "lyrics_test = csr_matrix(dat_test.loc[:,0:])\n",
    "data_test = hstack([gen_test, lyrics_test,test_label])\n",
    "data_test = pd.DataFrame.sparse.from_spmatrix(data_test)\n",
    "\n",
    "\n",
    "lyrics_tfidf_train = csr_matrix(dat_tfidf_train.loc[:,0:])\n",
    "data_tfidf_train = hstack([gen_train,lyrics_tfidf_train,train_label])\n",
    "data_tfidf_train = pd.DataFrame.sparse.from_spmatrix(data_tfidf_train)\n",
    "\n",
    "lyrics_tfidf_test = csr_matrix(dat_tfidf_test.loc[:,0:])\n",
    "data_tfidf_test = hstack([gen_test,lyrics_tfidf_test,test_label])\n",
    "data_tfidf_test = pd.DataFrame.sparse.from_spmatrix(data_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_name = [dictionary[i] for i in range(max(dictionary.keys())+1)]\n",
    "word_name = gen_des + word_name + ['label']\n",
    "data_tfidf_test.columns = word_name\n",
    "data_tfidf_train.columns = word_name\n",
    "data_train.columns = word_name\n",
    "data_test.columns = word_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_18576\\3770692225.py:1: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  data_tfidf_train.to_csv(\"data/train_tfidf_data.csv\")\n",
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_18576\\3770692225.py:2: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  data_tfidf_test.to_csv(\"data/test_tfidf_data.csv\")\n",
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_18576\\3770692225.py:12: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  data_train.to_csv(\"data/train_data_all.csv\")\n",
      "C:\\Users\\xuzhi\\AppData\\Local\\Temp\\ipykernel_18576\\3770692225.py:13: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  data_test.to_csv(\"data/test_data_all.csv\")\n"
     ]
    }
   ],
   "source": [
    "data_tfidf_train.to_csv(\"data/train_tfidf_data.csv\")\n",
    "data_tfidf_test.to_csv(\"data/test_tfidf_data.csv\")\n",
    "data_train = hstack([lyrics_train,train_label])\n",
    "data_train = pd.DataFrame.sparse.from_spmatrix(data_train)\n",
    "data_test = hstack([lyrics_test,test_label])\n",
    "data_test = pd.DataFrame.sparse.from_spmatrix(data_test)\n",
    "word_name = [dictionary[i] for i in range(max(dictionary.keys())+1)]\n",
    "word_name = word_name+['label']\n",
    "data_train.columns = word_name\n",
    "data_test.columns = word_name\n",
    "\n",
    "data_train.to_csv(\"data/train_data_all.csv\")\n",
    "data_test.to_csv(\"data/test_data_all.csv\")\n",
    "df_train.to_csv(\"data/train_other.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4721030042918455\n",
      "2.9527896995708156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],np.array(df_train[\"label\"]))\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:(data_tfidf_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == df_test[\"label\"])/len(pred))\n",
    "print(np.mean((pred-df_test[\"label\"])**2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct Use of Multinomial Logistic Regression's Performance is very bad.\n",
    "\n",
    "Hence, we consider here multi logistic scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "label_60 = df_train[\"label\"]==0\n",
    "mr60 = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_60)\n",
    "label_70 = df_train[\"label\"]==1\n",
    "mr70 = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_70)\n",
    "label_80 = df_train[\"label\"]==2\n",
    "mr80 = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_80)\n",
    "label_90 = df_train[\"label\"]==3\n",
    "mr90 = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_90)\n",
    "label_00 = df_train[\"label\"]==4\n",
    "mr00 = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_00)\n",
    "label_10 = df_train[\"label\"]==5\n",
    "mr10 = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_10)\n",
    "\n",
    "def predict_multi_logit(df):\n",
    "    prob60 = mr60.predict_log_proba(df)[:,1]\n",
    "    prob70 = mr70.predict_log_proba(df)[:,1]\n",
    "    prob80 = mr80.predict_log_proba(df)[:,1]\n",
    "    prob90 = mr90.predict_log_proba(df)[:,1]\n",
    "    prob00 = mr00.predict_log_proba(df)[:,1]\n",
    "    prob10 = mr10.predict_log_proba(df)[:,1]\n",
    "    prob = pd.DataFrame([prob60,prob70,prob80,prob90,prob00,prob10])\n",
    "    return prob.apply(np.argmax,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_multi_logit(data_tfidf_test.iloc[:,:(data_tfidf_train.shape[1]-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4721030042918455\n"
     ]
    }
   ],
   "source": [
    "print(sum(np.array(pred) == np.array(df_test[\"label\"]))/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8390557939914163\n"
     ]
    }
   ],
   "source": [
    "label_60 = df_train[\"label\"]==0\n",
    "label_60_test = df_test[\"label\"]==0\n",
    "\n",
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_60)\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:(data_tfidf_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == label_60_test)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8369098712446352\n"
     ]
    }
   ],
   "source": [
    "label_70 = df_train[\"label\"]==1\n",
    "label_70_test = df_test[\"label\"]==1\n",
    "\n",
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_70)\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:(data_tfidf_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == label_70_test)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869098712446352\n"
     ]
    }
   ],
   "source": [
    "label_80 = df_train[\"label\"]==2\n",
    "label_80_test = df_test[\"label\"]==2\n",
    "\n",
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_80)\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:(data_tfidf_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == label_80_test)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8347639484978541\n"
     ]
    }
   ],
   "source": [
    "label_90 = df_train[\"label\"]==3\n",
    "label_90_test = df_test[\"label\"]==3\n",
    "\n",
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_90)\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:(data_tfidf_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == label_90_test)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869098712446352\n"
     ]
    }
   ],
   "source": [
    "label_00 = df_train[\"label\"]==4\n",
    "label_00_test = df_test[\"label\"]==4\n",
    "\n",
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_00)\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:(data_tfidf_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == label_00_test)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8583690987124464\n"
     ]
    }
   ],
   "source": [
    "label_10 = df_train[\"label\"]==5\n",
    "label_10_test = df_test[\"label\"]==5\n",
    "\n",
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],label_10)\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:(data_tfidf_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == label_10_test)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283261802575107\n"
     ]
    }
   ],
   "source": [
    "label_10 = df_train[\"label\"]==5\n",
    "label_10_test = df_test[\"label\"]==5\n",
    "\n",
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:len(gen_des)],label_10)\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:len(gen_des)])\n",
    "\n",
    "print(sum(pred == label_10_test)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44206008583690987\n",
      "3.0622317596566524\n"
     ]
    }
   ],
   "source": [
    "mr = LogisticRegression(penalty='l1',solver='liblinear').fit(data_tfidf_train.iloc[:,:(data_tfidf_train.shape[1]-1)],np.array(df_train[\"label\"]))\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:(data_tfidf_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == df_test[\"label\"])/len(pred))\n",
    "print(np.mean((pred-df_test[\"label\"])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3540772532188841\n",
      "4.954935622317596\n"
     ]
    }
   ],
   "source": [
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:len(gen_des)],np.array(df_train[\"label\"]))\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:len(gen_des)])\n",
    "\n",
    "print(sum(pred == df_test[\"label\"])/len(pred))\n",
    "print(np.mean((pred-df_test[\"label\"])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4356223175965665\n",
      "2.875536480686695\n"
     ]
    }
   ],
   "source": [
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,len(gen_des):(data_tfidf_train.shape[1]-1)],np.array(df_train[\"label\"]))\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,len(gen_des):(data_tfidf_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == df_test[\"label\"])/len(pred))\n",
    "print(np.mean((pred-df_test[\"label\"])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39914163090128757\n",
      "2.8648068669527897\n"
     ]
    }
   ],
   "source": [
    "mr = LogisticRegression(penalty='l1',solver=\"liblinear\").fit(data_train.iloc[:,:(data_train.shape[1]-1)],np.array(df_train[\"label\"]))\n",
    "pred = mr.predict(data_test.iloc[:,:(data_train.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == df_test[\"label\"])/len(pred))\n",
    "print(np.mean((pred-df_test[\"label\"])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC \n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# clf = make_pipeline(StandardScaler(with_mean=False),SVC(gamma='auto'))\n",
    "# clf.fit(data_train.iloc[:,:(data_train.shape[1]-1)],np.array(df_train[\"label\"]))\n",
    "# pred = clf.predict(data_test.iloc[:,:(data_train.shape[1]-1)])\n",
    "\n",
    "# print(sum(pred == df_test[\"label\"])/len(pred))\n",
    "# print(np.mean((pred-df_test[\"label\"])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "# krr = KernelRidge(kernel=\"rbf\")\n",
    "# krr.fit(data_train.iloc[:,:(data_train.shape[1]-1)],np.array(df_train[\"label\"]))\n",
    "# pred = krr.predict(data_test.iloc[:,:(data_test.shape[1]-1)])\n",
    "\n",
    "# print(sum(pred == df_test[\"label\"])/len(pred))\n",
    "# print(np.mean((pred-df_test[\"label\"])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# np.random.seed(3701)\n",
    "# idx60 = []\n",
    "# label_60 = df_train[\"label\"]==0\n",
    "# num_60 = sum(label_60==0)\n",
    "# label_60 = list(label_60)\n",
    "# for i in range(len(label_60)):\n",
    "#     if label_60[i]:\n",
    "#         idx60.append(i)\n",
    "# boot60 = np.random.choice(idx60,num_60,replace=True)\n",
    "# dat_train_sp = csr_matrix(dat_train.iloc[:,:dat_train.shape[1]])\n",
    "# dat_train_60 = csr_matrix(dat_train.loc[idx60,:dat_train.shape[1]])\n",
    "# dat_train_60 = vstack([dat_train_sp,dat_train_60])\n",
    "# test_label_60 = np.vstack(np.array(df_test[\"label\"]),np.array(df_test.loc[idx60,\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"label\"] = np.zeros(df_train.shape[0])\n",
    "bins = [1990,np.inf]\n",
    "labels = [0,1]\n",
    "df_train[\"label\"] = np.where(df_train[\"year\"] < bins[0], labels[0],labels[1])\n",
    "\n",
    "df_test[\"label\"] = np.zeros(df_test.shape[0])\n",
    "df_test[\"label\"] = np.where(df_test[\"year\"] < bins[0], labels[0],labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6738197424892703\n"
     ]
    }
   ],
   "source": [
    "mr = LogisticRegression(penalty='l2',dual=True,solver=\"liblinear\").fit(data_tfidf_train.iloc[:,:len(gen_des)],df_train[\"label\"])\n",
    "pred = mr.predict(data_tfidf_test.iloc[:,:len(gen_des)])\n",
    "\n",
    "print(sum(pred == df_test[\"label\"])/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(dual=True, solver=&#x27;liblinear&#x27;),\n",
       "             n_jobs=4,\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e+03, 2.81526946e+01, 1.45160752e+01, 9.88336540e+00,\n",
       "       7.54939737e+00, 6.14277720e+00, 5.20205500e+00, 4.52839672e+00,\n",
       "       4.02203123e+00, 3.62738895e+00, 3.31106392e+00, 3.05176552e+00,\n",
       "       2.83528242e+00, 2.65176581e+00, 2.49417454e+00, 2.35734107e+00,\n",
       "       2.2373...\n",
       "       7.68627211e-01, 7.63039981e-01, 7.57584985e-01, 7.52257350e-01,\n",
       "       7.47052442e-01, 7.41965852e-01, 7.36993385e-01, 7.32131044e-01,\n",
       "       7.27375019e-01, 7.22721677e-01, 7.18167553e-01, 7.13709336e-01,\n",
       "       7.09343865e-01, 7.05068119e-01, 7.00879207e-01, 6.96774365e-01,\n",
       "       6.92750947e-01, 6.88806418e-01, 6.84938350e-01, 6.81144414e-01,\n",
       "       6.77422378e-01, 6.73770098e-01, 6.70185520e-01, 6.66666667e-01])},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LogisticRegression(dual=True, solver=&#x27;liblinear&#x27;),\n",
       "             n_jobs=4,\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e+03, 2.81526946e+01, 1.45160752e+01, 9.88336540e+00,\n",
       "       7.54939737e+00, 6.14277720e+00, 5.20205500e+00, 4.52839672e+00,\n",
       "       4.02203123e+00, 3.62738895e+00, 3.31106392e+00, 3.05176552e+00,\n",
       "       2.83528242e+00, 2.65176581e+00, 2.49417454e+00, 2.35734107e+00,\n",
       "       2.2373...\n",
       "       7.68627211e-01, 7.63039981e-01, 7.57584985e-01, 7.52257350e-01,\n",
       "       7.47052442e-01, 7.41965852e-01, 7.36993385e-01, 7.32131044e-01,\n",
       "       7.27375019e-01, 7.22721677e-01, 7.18167553e-01, 7.13709336e-01,\n",
       "       7.09343865e-01, 7.05068119e-01, 7.00879207e-01, 6.96774365e-01,\n",
       "       6.92750947e-01, 6.88806418e-01, 6.84938350e-01, 6.81144414e-01,\n",
       "       6.77422378e-01, 6.73770098e-01, 6.70185520e-01, 6.66666667e-01])},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(dual=True, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(dual=True, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(dual=True, solver='liblinear'),\n",
       "             n_jobs=4,\n",
       "             param_grid={'C': array([1.00000000e+03, 2.81526946e+01, 1.45160752e+01, 9.88336540e+00,\n",
       "       7.54939737e+00, 6.14277720e+00, 5.20205500e+00, 4.52839672e+00,\n",
       "       4.02203123e+00, 3.62738895e+00, 3.31106392e+00, 3.05176552e+00,\n",
       "       2.83528242e+00, 2.65176581e+00, 2.49417454e+00, 2.35734107e+00,\n",
       "       2.2373...\n",
       "       7.68627211e-01, 7.63039981e-01, 7.57584985e-01, 7.52257350e-01,\n",
       "       7.47052442e-01, 7.41965852e-01, 7.36993385e-01, 7.32131044e-01,\n",
       "       7.27375019e-01, 7.22721677e-01, 7.18167553e-01, 7.13709336e-01,\n",
       "       7.09343865e-01, 7.05068119e-01, 7.00879207e-01, 6.96774365e-01,\n",
       "       6.92750947e-01, 6.88806418e-01, 6.84938350e-01, 6.81144414e-01,\n",
       "       6.77422378e-01, 6.73770098e-01, 6.70185520e-01, 6.66666667e-01])},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':1/ np.log(np.linspace(np.exp(1e-3),np.exp(1.5),num=100,dtype=np.float64))}\n",
    "logclf = LogisticRegression(penalty=\"l2\",dual=True,solver=\"liblinear\")\n",
    "clf = GridSearchCV(logclf,param_grid=parameters,\n",
    "                   scoring='f1',n_jobs=4)\n",
    "clf.fit(data_tfidf_train.iloc[:,:(data_train.shape[1]-1)],df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1.41180372, 1.2727303 , 1.22065654, 1.2714325 , 1.52368474,\n",
      "       1.51715236, 1.40956945, 1.49648304, 1.52737727, 1.57335234,\n",
      "       1.53335724, 1.57915368, 1.546942  , 1.76027193, 1.56390519,\n",
      "       1.60132275, 1.70574627, 1.46470299, 1.60676522, 1.40437431,\n",
      "       1.4265183 , 1.38369999, 1.41751981, 1.39101629, 1.49465404,\n",
      "       1.48332739, 1.45793247, 1.3847281 , 1.53913317, 1.46287117,\n",
      "       1.45350394, 1.49493423, 1.37179093, 1.56450915, 1.50234694,\n",
      "       1.48528709, 1.75690951, 1.62265148, 1.50505385, 1.58115115,\n",
      "       1.46761723, 1.55904469, 1.59301558, 1.59314494, 1.63218269,\n",
      "       1.47640834, 1.55742393, 1.50661755, 1.64142399, 1.4678205 ,\n",
      "       1.51535621, 1.55767283, 1.44833984, 1.52841578, 1.4756609 ,\n",
      "       1.40899334, 1.53922544, 1.55364232, 1.60864391, 1.57363257,\n",
      "       1.65725241, 1.52789621, 1.48743582, 1.65867229, 1.48501925,\n",
      "       1.5037323 , 1.4991365 , 1.47330127, 1.54285359, 1.4818615 ,\n",
      "       1.53757129, 1.57600589, 1.67857423, 1.55647378, 1.58186693,\n",
      "       1.67151904, 1.51650119, 1.50056143, 1.60251517, 1.44506478,\n",
      "       1.55971398, 1.52181978, 1.53640547, 1.59248395, 1.53096957,\n",
      "       1.55051885, 1.54261327, 1.47476287, 1.63344359, 1.60238338,\n",
      "       1.53192773, 1.51396403, 1.60994763, 1.53800378, 1.47701774,\n",
      "       1.55930433, 1.57571974, 1.49679317, 1.55581417, 1.43879919]),\n",
      " 'mean_score_time': array([0.17482815, 0.11210022, 0.11052999, 0.1347353 , 0.13158975,\n",
      "       0.12270484, 0.1464489 , 0.15200696, 0.14299207, 0.161484  ,\n",
      "       0.16567483, 0.15775485, 0.17333174, 0.16153193, 0.16802626,\n",
      "       0.27227087, 0.18793626, 0.22090874, 0.16724477, 0.15353813,\n",
      "       0.15275683, 0.13743086, 0.12295785, 0.13466115, 0.13739586,\n",
      "       0.16907845, 0.1363349 , 0.11708379, 0.17283192, 0.17275062,\n",
      "       0.22909975, 0.19506049, 0.26478443, 0.16811314, 0.15760541,\n",
      "       0.15442209, 0.18077383, 0.16668019, 0.15748878, 0.17338448,\n",
      "       0.16283131, 0.17690892, 0.14824028, 0.14381552, 0.14895024,\n",
      "       0.18421831, 0.2089242 , 0.27436309, 0.14323478, 0.16995125,\n",
      "       0.15720086, 0.15156007, 0.14580364, 0.1516387 , 0.16432085,\n",
      "       0.14784718, 0.13574748, 0.17104545, 0.15935922, 0.26370296,\n",
      "       0.20521088, 0.23310976, 0.21474991, 0.17245808, 0.16246848,\n",
      "       0.16127934, 0.14544559, 0.12575421, 0.17079797, 0.12664685,\n",
      "       0.15440669, 0.13932786, 0.16605692, 0.1457458 , 0.15995326,\n",
      "       0.17032318, 0.25799546, 0.21038289, 0.21361895, 0.17464986,\n",
      "       0.15606194, 0.13598413, 0.16774516, 0.12372236, 0.15226088,\n",
      "       0.15907159, 0.13500743, 0.15646358, 0.12806568, 0.17787056,\n",
      "       0.17488122, 0.24418912, 0.183676  , 0.24333706, 0.14685221,\n",
      "       0.15427847, 0.19581623, 0.14469395, 0.13703976, 0.1196209 ]),\n",
      " 'mean_test_score': array([0.68126234, 0.69370942, 0.69657346, 0.69979864, 0.7003143 ,\n",
      "       0.69948519, 0.70091311, 0.70164725, 0.70356279, 0.70375637,\n",
      "       0.70496705, 0.70560711, 0.70481703, 0.70509002, 0.70338045,\n",
      "       0.70370938, 0.70461578, 0.704162  , 0.7043052 , 0.70320961,\n",
      "       0.7025573 , 0.70179426, 0.70181845, 0.70043441, 0.69960539,\n",
      "       0.70013436, 0.70045113, 0.70088422, 0.70203013, 0.70251671,\n",
      "       0.70301382, 0.70223586, 0.70220152, 0.70166116, 0.70207885,\n",
      "       0.70146926, 0.70227548, 0.7018617 , 0.70195861, 0.70201837,\n",
      "       0.70232817, 0.70133226, 0.70103321, 0.70045846, 0.70038003,\n",
      "       0.70101288, 0.70088741, 0.700927  , 0.70029706, 0.70037596,\n",
      "       0.70025352, 0.70056737, 0.70176583, 0.70157289, 0.70127384,\n",
      "       0.70098903, 0.70086419, 0.70111411, 0.70128564, 0.70110099,\n",
      "       0.70091173, 0.70086022, 0.70079593, 0.6995485 , 0.69901246,\n",
      "       0.69819842, 0.69802745, 0.69813293, 0.69860463, 0.69860921,\n",
      "       0.69882974, 0.69877866, 0.69841051, 0.69878472, 0.6992121 ,\n",
      "       0.69950729, 0.69875442, 0.69833139, 0.69833139, 0.69833758,\n",
      "       0.69796575, 0.69796575, 0.69766465, 0.69766465, 0.69859171,\n",
      "       0.69896102, 0.69945242, 0.69983547, 0.6995356 , 0.6991653 ,\n",
      "       0.69919384, 0.69907114, 0.6988574 , 0.6988574 , 0.69947373,\n",
      "       0.69953611, 0.6995233 , 0.69934208, 0.69970749, 0.70001051]),\n",
      " 'param_C': masked_array(data=[999.999999999957, 28.152694590686846,\n",
      "                   14.516075201392352, 9.883365399612996,\n",
      "                   7.549397372293015, 6.142777196188211,\n",
      "                   5.2020549956366295, 4.528396722612537,\n",
      "                   4.022031232076927, 3.627388950034001,\n",
      "                   3.311063919435153, 3.051765518525317,\n",
      "                   2.835282423978841, 2.6517658140026423,\n",
      "                   2.4941745447057917, 2.357341073095718,\n",
      "                   2.2373870328258945, 2.131344729129954,\n",
      "                   2.0369046000609963, 1.9522423051277504,\n",
      "                   1.8758976116041692, 1.8066878362071324,\n",
      "                   1.743644861638723, 1.68596856205287, 1.63299185730551,\n",
      "                   1.5841541437381006, 1.5389808488300376,\n",
      "                   1.4970675237985043, 1.458067340875958,\n",
      "                   1.4216811743078501, 1.387649662821591,\n",
      "                   1.3557468065891494, 1.3257747633464523,\n",
      "                   1.2975595895527716, 1.2709477322123233,\n",
      "                   1.2458031213707192, 1.2220047466008064,\n",
      "                   1.1994446260003322, 1.1780260954661999,\n",
      "                   1.15766236081527, 1.1382752667982348,\n",
      "                   1.1197942460122818, 1.1021554177590727,\n",
      "                   1.0853008124627457, 1.0691777016927655,\n",
      "                   1.053738017381117, 1.038937846675022,\n",
      "                   1.0247369911723416, 1.0110985811607451,\n",
      "                   0.9979887370117089, 0.9853762711351648,\n",
      "                   0.9732324249341366, 0.9615306360534307,\n",
      "                   0.9502463319261671, 0.9393567462134412,\n",
      "                   0.9288407552271789, 0.9186787318415859,\n",
      "                   0.9088524147483711, 0.8993447912064818,\n",
      "                   0.8901399916875984, 0.8812231950315788,\n",
      "                   0.8725805429076167, 0.8641990625320911,\n",
      "                   0.8560665967271608, 0.8481717405185212,\n",
      "                   0.8405037835692901, 0.8330526578321079,\n",
      "                   0.8258088898752316, 0.8187635574023548,\n",
      "                   0.8119082495414989, 0.8052350305267889,\n",
      "                   0.7987364064392701, 0.792405294709956,\n",
      "                   0.7862349961207863, 0.7802191690677128,\n",
      "                   0.774351805875239, 0.7686272109738889,\n",
      "                   0.7630399807716357, 0.7575849850676277,\n",
      "                   0.7522573498718779, 0.7470524415082036,\n",
      "                   0.7419658518897948, 0.7369933848675689,\n",
      "                   0.7321310435610763, 0.7273750185902959,\n",
      "                   0.72272167713434, 0.7181675527499481,\n",
      "                   0.7137093358888165, 0.709343865058336,\n",
      "                   0.705068118575292, 0.7008792068665387,\n",
      "                   0.696774365274717, 0.6927509473307042,\n",
      "                   0.688806418457782, 0.6849383500754845,\n",
      "                   0.6811444140737711, 0.6774223776306202,\n",
      "                   0.6737700983483443, 0.6701855196859479,\n",
      "                   0.6666666666666666],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'C': 999.999999999957},\n",
      "            {'C': 28.152694590686846},\n",
      "            {'C': 14.516075201392352},\n",
      "            {'C': 9.883365399612996},\n",
      "            {'C': 7.549397372293015},\n",
      "            {'C': 6.142777196188211},\n",
      "            {'C': 5.2020549956366295},\n",
      "            {'C': 4.528396722612537},\n",
      "            {'C': 4.022031232076927},\n",
      "            {'C': 3.627388950034001},\n",
      "            {'C': 3.311063919435153},\n",
      "            {'C': 3.051765518525317},\n",
      "            {'C': 2.835282423978841},\n",
      "            {'C': 2.6517658140026423},\n",
      "            {'C': 2.4941745447057917},\n",
      "            {'C': 2.357341073095718},\n",
      "            {'C': 2.2373870328258945},\n",
      "            {'C': 2.131344729129954},\n",
      "            {'C': 2.0369046000609963},\n",
      "            {'C': 1.9522423051277504},\n",
      "            {'C': 1.8758976116041692},\n",
      "            {'C': 1.8066878362071324},\n",
      "            {'C': 1.743644861638723},\n",
      "            {'C': 1.68596856205287},\n",
      "            {'C': 1.63299185730551},\n",
      "            {'C': 1.5841541437381006},\n",
      "            {'C': 1.5389808488300376},\n",
      "            {'C': 1.4970675237985043},\n",
      "            {'C': 1.458067340875958},\n",
      "            {'C': 1.4216811743078501},\n",
      "            {'C': 1.387649662821591},\n",
      "            {'C': 1.3557468065891494},\n",
      "            {'C': 1.3257747633464523},\n",
      "            {'C': 1.2975595895527716},\n",
      "            {'C': 1.2709477322123233},\n",
      "            {'C': 1.2458031213707192},\n",
      "            {'C': 1.2220047466008064},\n",
      "            {'C': 1.1994446260003322},\n",
      "            {'C': 1.1780260954661999},\n",
      "            {'C': 1.15766236081527},\n",
      "            {'C': 1.1382752667982348},\n",
      "            {'C': 1.1197942460122818},\n",
      "            {'C': 1.1021554177590727},\n",
      "            {'C': 1.0853008124627457},\n",
      "            {'C': 1.0691777016927655},\n",
      "            {'C': 1.053738017381117},\n",
      "            {'C': 1.038937846675022},\n",
      "            {'C': 1.0247369911723416},\n",
      "            {'C': 1.0110985811607451},\n",
      "            {'C': 0.9979887370117089},\n",
      "            {'C': 0.9853762711351648},\n",
      "            {'C': 0.9732324249341366},\n",
      "            {'C': 0.9615306360534307},\n",
      "            {'C': 0.9502463319261671},\n",
      "            {'C': 0.9393567462134412},\n",
      "            {'C': 0.9288407552271789},\n",
      "            {'C': 0.9186787318415859},\n",
      "            {'C': 0.9088524147483711},\n",
      "            {'C': 0.8993447912064818},\n",
      "            {'C': 0.8901399916875984},\n",
      "            {'C': 0.8812231950315788},\n",
      "            {'C': 0.8725805429076167},\n",
      "            {'C': 0.8641990625320911},\n",
      "            {'C': 0.8560665967271608},\n",
      "            {'C': 0.8481717405185212},\n",
      "            {'C': 0.8405037835692901},\n",
      "            {'C': 0.8330526578321079},\n",
      "            {'C': 0.8258088898752316},\n",
      "            {'C': 0.8187635574023548},\n",
      "            {'C': 0.8119082495414989},\n",
      "            {'C': 0.8052350305267889},\n",
      "            {'C': 0.7987364064392701},\n",
      "            {'C': 0.792405294709956},\n",
      "            {'C': 0.7862349961207863},\n",
      "            {'C': 0.7802191690677128},\n",
      "            {'C': 0.774351805875239},\n",
      "            {'C': 0.7686272109738889},\n",
      "            {'C': 0.7630399807716357},\n",
      "            {'C': 0.7575849850676277},\n",
      "            {'C': 0.7522573498718779},\n",
      "            {'C': 0.7470524415082036},\n",
      "            {'C': 0.7419658518897948},\n",
      "            {'C': 0.7369933848675689},\n",
      "            {'C': 0.7321310435610763},\n",
      "            {'C': 0.7273750185902959},\n",
      "            {'C': 0.72272167713434},\n",
      "            {'C': 0.7181675527499481},\n",
      "            {'C': 0.7137093358888165},\n",
      "            {'C': 0.709343865058336},\n",
      "            {'C': 0.705068118575292},\n",
      "            {'C': 0.7008792068665387},\n",
      "            {'C': 0.696774365274717},\n",
      "            {'C': 0.6927509473307042},\n",
      "            {'C': 0.688806418457782},\n",
      "            {'C': 0.6849383500754845},\n",
      "            {'C': 0.6811444140737711},\n",
      "            {'C': 0.6774223776306202},\n",
      "            {'C': 0.6737700983483443},\n",
      "            {'C': 0.6701855196859479},\n",
      "            {'C': 0.6666666666666666}],\n",
      " 'rank_test_score': array([100,  99,  98,  60,  54,  68,  41,  29,  10,   8,   3,   1,   4,\n",
      "         2,  11,   9,   5,   7,   6,  12,  14,  26,  25,  51,  62,  57,\n",
      "        50,  44,  21,  15,  13,  18,  19,  28,  20,  31,  17,  24,  23,\n",
      "        22,  16,  32,  37,  49,  52,  38,  43,  40,  55,  53,  56,  48,\n",
      "        27,  30,  34,  39,  45,  35,  33,  36,  42,  46,  47,  63,  76,\n",
      "        91,  93,  92,  85,  84,  80,  82,  87,  81,  72,  67,  83,  89,\n",
      "        89,  88,  94,  94,  96,  96,  86,  77,  70,  59,  65,  74,  73,\n",
      "        75,  78,  78,  69,  64,  66,  71,  61,  58]),\n",
      " 'split0_test_score': array([0.52380952, 0.51912568, 0.51219512, 0.50543478, 0.50271739,\n",
      "       0.49795918, 0.49251701, 0.49459459, 0.49597855, 0.49666222,\n",
      "       0.49800266, 0.5       , 0.49802372, 0.49868766, 0.4947644 ,\n",
      "       0.49411765, 0.4921875 , 0.4961039 , 0.49805447, 0.4961039 ,\n",
      "       0.49935317, 0.49935317, 0.49935317, 0.49870801, 0.49290323,\n",
      "       0.49420849, 0.49420849, 0.49423816, 0.49744898, 0.49744898,\n",
      "       0.49681529, 0.49681529, 0.49809403, 0.49746193, 0.49936629,\n",
      "       0.50126582, 0.50316056, 0.50252525, 0.50252525, 0.50252525,\n",
      "       0.50125945, 0.49874055, 0.49874055, 0.49874055, 0.49748744,\n",
      "       0.5       , 0.49937265, 0.49937265, 0.49874687, 0.49874687,\n",
      "       0.49874687, 0.5       , 0.5       , 0.50187266, 0.50187266,\n",
      "       0.50124688, 0.50062267, 0.50062267, 0.50062267, 0.50062267,\n",
      "       0.49875312, 0.5       , 0.49875312, 0.49376559, 0.49376559,\n",
      "       0.49315068, 0.49315068, 0.49315068, 0.49315068, 0.49315068,\n",
      "       0.49502488, 0.49440994, 0.49192547, 0.49379653, 0.49443758,\n",
      "       0.49443758, 0.49382716, 0.49321825, 0.49321825, 0.49321825,\n",
      "       0.49321825, 0.49321825, 0.49321825, 0.49321825, 0.49692497,\n",
      "       0.4987715 , 0.5012285 , 0.50245098, 0.50245098, 0.50245098,\n",
      "       0.5006135 , 0.5       , 0.50183599, 0.50183599, 0.50366748,\n",
      "       0.50549451, 0.50549451, 0.50366748, 0.50549451, 0.50549451]),\n",
      " 'split1_test_score': array([0.72748268, 0.75231481, 0.75789474, 0.76796231, 0.76796231,\n",
      "       0.76905041, 0.77283372, 0.77699531, 0.78077374, 0.7826087 ,\n",
      "       0.78546307, 0.78403756, 0.78220141, 0.78220141, 0.78220141,\n",
      "       0.78546307, 0.78638498, 0.78117647, 0.77974087, 0.77738516,\n",
      "       0.7759434 , 0.77502945, 0.77213695, 0.77304965, 0.77159763,\n",
      "       0.77159763, 0.77159763, 0.77342823, 0.77633136, 0.77725118,\n",
      "       0.77725118, 0.77725118, 0.77580071, 0.77434679, 0.77434679,\n",
      "       0.77088305, 0.77088305, 0.77180406, 0.77180406, 0.77272727,\n",
      "       0.77218225, 0.77365269, 0.77365269, 0.77511962, 0.77511962,\n",
      "       0.77419355, 0.77419355, 0.77511962, 0.77272727, 0.77272727,\n",
      "       0.77125749, 0.77125749, 0.77125749, 0.77125749, 0.77125749,\n",
      "       0.77272727, 0.77272727, 0.77272727, 0.77272727, 0.77180406,\n",
      "       0.77272727, 0.77272727, 0.77365269, 0.77365269, 0.77458034,\n",
      "       0.77403846, 0.77403846, 0.77403846, 0.77403846, 0.77256318,\n",
      "       0.77256318, 0.77349398, 0.77349398, 0.77349398, 0.77349398,\n",
      "       0.77496992, 0.77403846, 0.77403846, 0.77403846, 0.77256318,\n",
      "       0.77163462, 0.77163462, 0.77163462, 0.77163462, 0.77256318,\n",
      "       0.77256318, 0.77256318, 0.77403846, 0.77403846, 0.77403846,\n",
      "       0.77403846, 0.77403846, 0.77256318, 0.77256318, 0.77256318,\n",
      "       0.77256318, 0.77256318, 0.77256318, 0.77256318, 0.77256318]),\n",
      " 'split2_test_score': array([0.75275938, 0.76126126, 0.7674685 , 0.7718894 , 0.77546296,\n",
      "       0.77958237, 0.7804878 , 0.78230501, 0.78413069, 0.78362573,\n",
      "       0.78688525, 0.78823529, 0.78495887, 0.78495887, 0.78117647,\n",
      "       0.78209658, 0.78158205, 0.78014184, 0.78199052, 0.78291815,\n",
      "       0.78147268, 0.77857143, 0.7794994 , 0.77658303, 0.77897252,\n",
      "       0.78031212, 0.78031212, 0.77737665, 0.77777778, 0.77777778,\n",
      "       0.77925211, 0.77536232, 0.77536232, 0.7738815 , 0.77294686,\n",
      "       0.77146312, 0.77146312, 0.76997579, 0.76997579, 0.76848485,\n",
      "       0.77184466, 0.76941748, 0.76792224, 0.76642336, 0.76642336,\n",
      "       0.76735688, 0.76735688, 0.76735688, 0.76735688, 0.76735688,\n",
      "       0.76735688, 0.76642336, 0.76941748, 0.76941748, 0.76792224,\n",
      "       0.76792224, 0.76792224, 0.76792224, 0.76792224, 0.76792224,\n",
      "       0.76792224, 0.76792224, 0.76792224, 0.76792224, 0.76642336,\n",
      "       0.7654921 , 0.7654921 , 0.7654921 , 0.7654921 , 0.76699029,\n",
      "       0.7654921 , 0.76492083, 0.76492083, 0.76492083, 0.76492083,\n",
      "       0.76492083, 0.76492083, 0.76341463, 0.76341463, 0.76492083,\n",
      "       0.76399027, 0.76399027, 0.76248477, 0.76248477, 0.76248477,\n",
      "       0.76248477, 0.76248477, 0.76097561, 0.76097561, 0.75912409,\n",
      "       0.75912409, 0.75912409, 0.75761267, 0.75761267, 0.75761267,\n",
      "       0.75609756, 0.75517661, 0.75609756, 0.75609756, 0.75761267]),\n",
      " 'split3_test_score': array([0.6981982 , 0.72417707, 0.73226545, 0.73526012, 0.73573923,\n",
      "       0.73153576, 0.73411765, 0.73027091, 0.73286052, 0.72985782,\n",
      "       0.72899408, 0.72813239, 0.72877358, 0.73090482, 0.72791519,\n",
      "       0.72727273, 0.73136095, 0.72985782, 0.72748815, 0.72985782,\n",
      "       0.72748815, 0.72748815, 0.72813239, 0.72511848, 0.72511848,\n",
      "       0.72511848, 0.72597865, 0.72597865, 0.72446556, 0.72597865,\n",
      "       0.72835113, 0.72835113, 0.72835113, 0.72921615, 0.73159145,\n",
      "       0.73159145, 0.73372781, 0.73286052, 0.73136095, 0.73222749,\n",
      "       0.73222749, 0.73072361, 0.73072361, 0.72662722, 0.72748815,\n",
      "       0.72813239, 0.72813239, 0.72813239, 0.72727273, 0.72641509,\n",
      "       0.72727273, 0.72727273, 0.73027091, 0.72941176, 0.72941176,\n",
      "       0.72641509, 0.72641509, 0.72641509, 0.72727273, 0.72727273,\n",
      "       0.72727273, 0.72576832, 0.72576832, 0.72576832, 0.72491145,\n",
      "       0.72491145, 0.7240566 , 0.7240566 , 0.72641509, 0.72641509,\n",
      "       0.72641509, 0.72641509, 0.72705882, 0.72705882, 0.72855464,\n",
      "       0.72855464, 0.72705882, 0.72705882, 0.72705882, 0.72705882,\n",
      "       0.72705882, 0.72705882, 0.72705882, 0.72705882, 0.72705882,\n",
      "       0.72705882, 0.72705882, 0.72705882, 0.72555948, 0.72555948,\n",
      "       0.72555948, 0.72555948, 0.72491145, 0.72491145, 0.72491145,\n",
      "       0.72491145, 0.72576832, 0.72576832, 0.72576832, 0.72576832]),\n",
      " 'split4_test_score': array([0.7040619 , 0.71166827, 0.71304348, 0.7184466 , 0.71968962,\n",
      "       0.71929825, 0.72460938, 0.72407045, 0.72407045, 0.7260274 ,\n",
      "       0.7254902 , 0.72763029, 0.73012758, 0.72869736, 0.73084479,\n",
      "       0.72959685, 0.73156342, 0.73352999, 0.73425197, 0.72978304,\n",
      "       0.72852912, 0.72852912, 0.72997033, 0.72871287, 0.72943508,\n",
      "       0.72943508, 0.73015873, 0.73339941, 0.73412698, 0.73412698,\n",
      "       0.73339941, 0.73339941, 0.73339941, 0.73339941, 0.73214286,\n",
      "       0.73214286, 0.73214286, 0.73214286, 0.73412698, 0.73412698,\n",
      "       0.73412698, 0.73412698, 0.73412698, 0.73538157, 0.73538157,\n",
      "       0.73538157, 0.73538157, 0.73465347, 0.73538157, 0.73663366,\n",
      "       0.73663366, 0.73788328, 0.73788328, 0.73590504, 0.73590504,\n",
      "       0.73663366, 0.73663366, 0.73788328, 0.73788328, 0.73788328,\n",
      "       0.73788328, 0.73788328, 0.73788328, 0.73663366, 0.73538157,\n",
      "       0.73339941, 0.73339941, 0.73392681, 0.73392681, 0.73392681,\n",
      "       0.73465347, 0.73465347, 0.73465347, 0.73465347, 0.73465347,\n",
      "       0.73465347, 0.73392681, 0.73392681, 0.73392681, 0.73392681,\n",
      "       0.73392681, 0.73392681, 0.73392681, 0.73392681, 0.73392681,\n",
      "       0.73392681, 0.73392681, 0.73465347, 0.73465347, 0.73465347,\n",
      "       0.73663366, 0.73663366, 0.73736373, 0.73736373, 0.73861386,\n",
      "       0.73861386, 0.73861386, 0.73861386, 0.73861386, 0.73861386]),\n",
      " 'std_fit_time': array([0.07213621, 0.03469169, 0.03813951, 0.10147849, 0.12696942,\n",
      "       0.05408336, 0.10147755, 0.12126361, 0.10839626, 0.06776425,\n",
      "       0.07877139, 0.06908901, 0.14034606, 0.13612511, 0.06692357,\n",
      "       0.07373217, 0.23840286, 0.17974181, 0.11684816, 0.0915613 ,\n",
      "       0.14483922, 0.04747423, 0.10566622, 0.10427243, 0.13895122,\n",
      "       0.04259016, 0.10296651, 0.09693491, 0.0744056 , 0.09497421,\n",
      "       0.12365793, 0.2020297 , 0.14614043, 0.09976997, 0.05192403,\n",
      "       0.06407937, 0.05583556, 0.03749333, 0.0651729 , 0.07341795,\n",
      "       0.05764494, 0.07365779, 0.10200733, 0.1160617 , 0.11048986,\n",
      "       0.0803163 , 0.08809789, 0.03306896, 0.06933273, 0.05712483,\n",
      "       0.06298174, 0.10424668, 0.07410231, 0.04616277, 0.10945993,\n",
      "       0.0955195 , 0.06935166, 0.12944715, 0.05612976, 0.04459014,\n",
      "       0.15428856, 0.07848734, 0.05793975, 0.17228305, 0.10200206,\n",
      "       0.06576751, 0.18706389, 0.11408706, 0.07690041, 0.10356103,\n",
      "       0.1510492 , 0.07201671, 0.08859163, 0.08114979, 0.10207405,\n",
      "       0.12844399, 0.11683164, 0.14171597, 0.10247909, 0.03512086,\n",
      "       0.10325486, 0.04185794, 0.05221706, 0.09546327, 0.11825643,\n",
      "       0.0809948 , 0.07846908, 0.132981  , 0.03471547, 0.08675068,\n",
      "       0.14030495, 0.14173352, 0.06425375, 0.04684297, 0.10828242,\n",
      "       0.09835387, 0.07506193, 0.05505187, 0.05862039, 0.06232247]),\n",
      " 'std_score_time': array([0.03611288, 0.01307236, 0.01125862, 0.02575094, 0.03664958,\n",
      "       0.02885151, 0.02396601, 0.02825392, 0.03573544, 0.02602554,\n",
      "       0.01048981, 0.03979572, 0.02905364, 0.01672783, 0.03153108,\n",
      "       0.06340323, 0.05877532, 0.04585282, 0.01719691, 0.02599412,\n",
      "       0.02851272, 0.0352452 , 0.01132656, 0.03092213, 0.0208163 ,\n",
      "       0.0304489 , 0.01957698, 0.01211339, 0.04042066, 0.04291042,\n",
      "       0.04788497, 0.06376823, 0.04448673, 0.02836366, 0.0247701 ,\n",
      "       0.02420762, 0.01572723, 0.01665187, 0.02664733, 0.03167125,\n",
      "       0.02009454, 0.01464877, 0.03079065, 0.03502493, 0.02195151,\n",
      "       0.03943735, 0.06567512, 0.06284469, 0.0162412 , 0.02611588,\n",
      "       0.03799177, 0.0337342 , 0.03312708, 0.02892936, 0.02145467,\n",
      "       0.03555942, 0.02233399, 0.03610243, 0.03236352, 0.06907823,\n",
      "       0.03930485, 0.07405966, 0.05371837, 0.05300051, 0.02138977,\n",
      "       0.02247532, 0.0171386 , 0.01200267, 0.02617266, 0.0114024 ,\n",
      "       0.03145426, 0.01977011, 0.0217147 , 0.01336009, 0.02456491,\n",
      "       0.03491188, 0.03731179, 0.05340415, 0.05696231, 0.03237315,\n",
      "       0.02065481, 0.01981926, 0.02058581, 0.01415293, 0.02573525,\n",
      "       0.01572898, 0.02142383, 0.02546271, 0.01869054, 0.06079721,\n",
      "       0.03581959, 0.0466285 , 0.07592819, 0.05095705, 0.02522784,\n",
      "       0.01725184, 0.01587591, 0.01794808, 0.01840162, 0.02020958]),\n",
      " 'std_test_score': array([0.08105082, 0.08913823, 0.09415621, 0.09922292, 0.10089444,\n",
      "       0.10323508, 0.10639332, 0.10618467, 0.10660474, 0.10645382,\n",
      "       0.10679228, 0.10606172, 0.10619705, 0.10597249, 0.10690357,\n",
      "       0.10768687, 0.10879087, 0.10631566, 0.10554541, 0.10598539,\n",
      "       0.10411643, 0.10355235, 0.10339842, 0.10312526, 0.10559218,\n",
      "       0.10528407, 0.10536586, 0.10535966, 0.10454222, 0.1047396 ,\n",
      "       0.10526781, 0.10471443, 0.10400608, 0.10388734, 0.10306518,\n",
      "       0.1016337 , 0.10101682, 0.10113788, 0.10117084, 0.10115196,\n",
      "       0.10202539, 0.10280913, 0.10261264, 0.10248922, 0.10302727,\n",
      "       0.1020586 , 0.10230573, 0.10239066, 0.10229784, 0.10234071,\n",
      "       0.10217916, 0.10165336, 0.10220792, 0.10128446, 0.10108572,\n",
      "       0.10143015, 0.10167601, 0.10176512, 0.10180834, 0.10167936,\n",
      "       0.10254539, 0.10197856, 0.10260062, 0.10447564, 0.10428277,\n",
      "       0.10418965, 0.10414637, 0.1041824 , 0.10430398, 0.10428698,\n",
      "       0.10340329, 0.10370585, 0.1047201 , 0.10398232, 0.10381244,\n",
      "       0.10402512, 0.10399913, 0.10404911, 0.10404911, 0.10402712,\n",
      "       0.10377618, 0.10377618, 0.10358619, 0.10358619, 0.10225705,\n",
      "       0.1015288 , 0.10056001, 0.10015812, 0.10007837, 0.09985353,\n",
      "       0.10072179, 0.10096371, 0.09986362, 0.09986362, 0.09923842,\n",
      "       0.09834152, 0.09828139, 0.0991077 , 0.09838633, 0.09856171])}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7875536480686696\n",
      "PPV 0.7489177489177489\n",
      "PRECISION 0.8084112149532711\n"
     ]
    }
   ],
   "source": [
    "logclf = LogisticRegression(C=3.05,dual=True,penalty=\"l2\",solver=\"liblinear\")\n",
    "logclf.fit(np.array(data_tfidf_train.iloc[:,:(data_train.shape[1]-1)]),df_train[\"label\"])\n",
    "pred = logclf.predict(np.array(data_tfidf_test.iloc[:,:(data_test.shape[1]-1)]))\n",
    "\n",
    "print(sum(pred == df_test[\"label\"])/len(pred))\n",
    "print(\"PPV\",sum(pred[df_test[\"label\"]==1]==1)/len(pred[df_test[\"label\"]==1]))\n",
    "print(\"PRECISION\",sum(df_test.loc[pred==1,\"label\"]==1)/len(df_test.loc[pred==1,\"label\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing to generation\n",
    "Frequency may have some concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9399141630901288\n",
      "PPV 0.0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:162\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:203\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:211\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.index._unpack_bool_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39msum\u001b[39m(pred \u001b[39m==\u001b[39m data_test\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m])\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(pred))\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPPV\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39msum\u001b[39m(pred[data_test\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(pred[data_test\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPRECISION\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39msum\u001b[39m(data_test\u001b[39m.\u001b[39;49mloc[pred\u001b[39m==\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(data_test\u001b[39m.\u001b[39mloc[pred\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1246\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tup):\n\u001b[0;32m    964\u001b[0m     \u001b[39mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m    965\u001b[0m         \u001b[39m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m    966\u001b[0m         \u001b[39m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m--> 967\u001b[0m         section \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    969\u001b[0m         \u001b[39m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m    970\u001b[0m         \u001b[39m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m    971\u001b[0m         \u001b[39m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m    972\u001b[0m         \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[0;32m    973\u001b[0m             \u001b[39m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m    974\u001b[0m             \u001b[39m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1312\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[0;32m   1259\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4041\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4039\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4040\u001b[0m     \u001b[39mif\u001b[39;00m drop_level:\n\u001b[1;32m-> 4041\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[0;32m   4042\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4043\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "logclf = LogisticRegression(dual=True,penalty=\"l2\",solver=\"liblinear\")\n",
    "logclf.fit(data_tfidf_train.iloc[:,len(gen_des):(data_train.shape[1]-1)],data_train.iloc[:,1])\n",
    "pred = logclf.predict(data_tfidf_test.iloc[:,len(gen_des):(data_test.shape[1]-1)])\n",
    "\n",
    "print(sum(pred == data_test.iloc[:,1])/len(pred))\n",
    "print(\"PPV\",sum(pred[data_test.iloc[:,1]==1]==1)/len(pred[data_test.iloc[:,1]==1]))\n",
    "print(\"PRECISION\",sum(data_test.loc[pred==1,1]==1)/len(data_test.loc[pred==1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "4650    0.0\n",
      "4651    0.0\n",
      "4652    0.0\n",
      "4653    0.0\n",
      "4654    0.0\n",
      "Name: alternative, Length: 4655, dtype: Sparse[float64, 0]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(data_tfidf_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alternative      1\n",
      "country        200\n",
      "dance          175\n",
      "disco          128\n",
      "folk            49\n",
      "funk           120\n",
      "hip              2\n",
      "new              0\n",
      "pop            983\n",
      "r&b            529\n",
      "rap            157\n",
      "rock           948\n",
      "soul           374\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(np.sum(data_train.iloc[:,0:13],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1.4067885 , 0.07769131, 0.81636606, ..., 0.40091202, 0.46572522,\n",
      "        0.5508126 ]])\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(logclf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alternative', 'country', 'dance', 'disco', 'folk', 'funk', 'hip',\n",
       "       'new', 'pop', 'r&b',\n",
       "       ...\n",
       "       'hitta', 'hittas', 'rari', 'panda', 'offset', 'swalla', 'thun', 'cardi',\n",
       "       'roxanne', 'label'],\n",
       "      dtype='object', length=3887)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf_train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
