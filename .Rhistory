Pi.r[i,2] = 1
} else if (a<c[3]) {
Pi.r[i,3] = 1
} else if (a<c[4]) {
Pi.r[i,4] = 1
} else {
Pi.r[i,5] = 1
}
}
P.r = Pi.r%*%t(Theta.r)
idx.ori = order(colMeans(Pi.r))
X = matrix(rbinom(N*I,1,P.r),nrow=N)
XX = X%*%t(X)
D = rowSums(XX)
L = diag((D+1e-14)^(-1/2))%*%XX%*%diag((D+1e-14)^(-1/2))
L.evd = eigen(L)
L.cluster = kmeans(L.evd$vectors[,1:4],K,iter.max = 1e2, nstart=30,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
L.cluster = kmeans(L.evd$vectors[,1:5],K,iter.max = 1e2, nstart=30,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
L.cluster = kmeans(L.evd$vectors[,1:6],K,iter.max = 1e2, nstart=30,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
# D = rowSums(XX)
# L = diag(D^(-1/2))%*%XX%*%diag(D^(-1/2))
# L.off = L-diag(diag(L))
L.off.evd = eigen(XX)
L.off.cluster = kmeans(L.off.evd$vectors[,1:6],K,iter.max = 1e2, nstart=100,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.off.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.off.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.off.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.off.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.off.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
L.off.cluster = kmeans(L.off.evd$vectors[,1:5],K,iter.max = 1e2, nstart=100,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.off.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.off.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.off.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.off.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.off.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
plot(L.off.evd$values)
plot(L.off.evd$values[-1])
L.off.cluster = kmeans(L.off.evd$vectors[,1:4],K,iter.max = 1e2, nstart=100,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.off.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.off.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.off.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.off.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.off.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
L.off.cluster = kmeans(L.off.evd$vectors[,1:5],K,iter.max = 1e2, nstart=100,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.off.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.off.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.off.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.off.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.off.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
L.off.cluster = kmeans(L.off.evd$vectors[,1:2],K,iter.max = 1e2, nstart=100,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.off.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.off.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.off.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.off.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.off.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
XX.off = XX-diag(diag(XX))
# D = rowSums(XX.off)
# L = diag(D^(-1/2))%*%XX%*%diag(D^(-1/2))
# L.off = L-diag(diag(L))
L.off.evd = svd(XX.off)
L.off.cluster = kmeans(L.off.evd$u[,1:5],K,iter.max = 1e2, nstart=100,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.off.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.off.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.off.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.off.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.off.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
plot(L.off.evd$d)
plot(L.off.evd$d[-1])
XX.off = XX-diag(diag(XX))
D = rowSums(XX.off)
L = diag((D+1e-14)^(-1/2))%*%XX.off%*%diag((D+1e-14)^(-1/2))
L.evd = eigen(L)
L.cluster = kmeans(L.evd$vectors[,1:5],K,iter.max = 1e2, nstart=100,algorithm = "Lloyd")
Pi.est = matrix(rep(0,N*K),nrow=N)
for (i in 1:N) {
if (L.cluster$cluster[i] == 1){
Pi.est[i,1] = 1
} else if (L.cluster$cluster[i] == 2) {
Pi.est[i,2] = 1
} else if (L.cluster$cluster[i] == 3) {
Pi.est[i,3] = 1
} else if (L.cluster$cluster[i] == 4) {
Pi.est[i,4] = 1
} else if (L.cluster$cluster[i] == 5) {
Pi.est[i,5] = 1
}
}
idx.est = order(colMeans(Pi.est))
err = 0
for (i in 1:N) {
if (any(Pi.est[i,idx.est]!=Pi.r[i,idx.ori])){
err = err+1
}
}
err = err/N
err
knitr::opts_chunk$set(echo = TRUE)
brewer = read.table("brewer_data.txt",header=T,sep = "\t")
reviewer = read.table("reviewer_data.txt",header=T)
library(tidyverse)
brewer.dist = dist(brewer[,4:7],method = "euclidean")
hclust.complete = hclust(brewer.dist,method = "complete")
idx = cutree(hclust.complete,k=20)
plot(hclust.complete)
summary(as.factor(idx))
summary(as.factor(brewer$style))
hclust.single = hclust(brewer.dist,method = "single")
idx = cutree(hclust.single,k=20)
plot(hclust.single)
summary(as.factor(idx))
hclust.average = hclust(brewer.dist,method = "average")
idx = cutree(hclust.average,k=20)
plot(hclust.average)
idx = cutree(hclust.average,k=20)
summary(as.factor(idx))
hclust.median = hclust(brewer.dist,method = "median")
idx = cutree(hclust.median,k=20)
plot(hclust.median)
summary(as.factor(idx))
hclust.centroid = hclust(brewer.dist,method = "centroid")
idx = cutree(hclust.centroid,k=20)
plot(hclust.centroid)
idx = cutree(hclust.centroid,k=20)
summary(as.factor(idx))
hclust.mcquitty = hclust(reviewer.dist,method = "mcquitty")
brewer.dist = dist(brewer[,4:7],method = "euclidean")
reviewer.dist = dist(reviewer[,2:5],method = "euclidean")
hclust.complete = hclust(brewer.dist,method = "complete")
idx = cutree(hclust.complete,k=20)
plot(hclust.complete)
hclust.mcquitty = hclust(reviewer.dist,method = "mcquitty")
idx = cutree(hclust.mcquitty,k=3)
plot(hclust.mcquitty)
hclust.ward.D2 = hclust(reviewer.dist,method = "ward.D2")
idx = cutree(hclust.ward.D2,k=3)
plot(hclust.ward.D2)
hclust.mcquitty = hclust(brewer.dist,method = "mcquitty")
idx = cutree(brewer.mcquitty,k=20)
hclust.mcquitty = hclust(brewer.dist,method = "mcquitty")
idx = cutree(hclust.mcquitty,k=20)
plot(hclust.mcquitty)
summary(as.factor(idx))
?dist
reticulate::repl_python()
install.packages("topicmodels")
library(topicmodels)
install.packages("textmineR")
#-*-coding:utf-8-*-
library(glmnet)
# library(data.table)
# library(tictoc)
# library(parallel)
# library(foreach)
# library(doSNOW)
# numCores = 6
# cl = makeCluster(numCores)
# registerDoSNOW(cl)
dat_train = read.csv("data/train_data_all.csv")
setwd("D:/Programmes/Python/Lyrics-Generation-Analysis")
# library(data.table)
# library(tictoc)
# library(parallel)
# library(foreach)
# library(doSNOW)
# numCores = 6
# cl = makeCluster(numCores)
# registerDoSNOW(cl)
dat_train = read.csv("data/train_data_all.csv")
dat_train = dat_train[,-1]
dat_test = read.csv("data/test_data_all.csv")
dat_test = dat_test[,-1]
train_other = read.csv("data/train_other.csv")
dat_train = dat_train[,-1]
dat_test = dat_test[,-1]
tail(colnames(dat_train))
tail(colnames(dat_train),10)
# normalization of word frequency
var_max = max(dat_train[,14:(ncol(dat_train)-1)],axis=1)
dat_train[,14:(ncol(dat_train)-1)] = t(t(dat_train[,14:(ncol(dat_train)-1)])/var_max)
dat_test[,14:(ncol(dat_test)-1)] = t(t(dat_test[,14:(ncol(dat_test)-1)])/var_max)
# base model
# perform cross validation on elastic net
lam = log(seq(from = exp(1e-2), to = exp(2), length=500))
idx = rep(1:5,length.out=nrow(dat_train))
set.seed(516)
idx = sample(idx)
# ridge lambda = .7
set.seed(3701)
label_60 = dat_train$label.1
idx60 = (1:length(label_60))[label_60==0]
boot60 = sample(idx60,sum(label_60!=0)/2-sum(label_60==0),replace = T)
dat_train_60 = rbind(dat_train,dat_train[boot60,])
clf60 = glmnet(data.matrix(dat_train_60[,-ncol(dat_train)]),dat_train_60[,ncol(dat_train)]==0
,family="binomial",alpha = 0,lambda=.7)
label_70 = dat_train$label.1
idx70 = (1:length(label_70))[label_70==1]
boot70 = sample(idx70,sum(label_70!=1)/2-sum(label_70==1),replace = T)
dat_train_70 = rbind(dat_train,dat_train[boot70,])
clf70 = glmnet(data.matrix(dat_train_70[,-ncol(dat_train)]),dat_train_70[,ncol(dat_train)]==1
,family="binomial",alpha = 0,lambda=.5)
# ridge lambda = 1.4
set.seed(3701)
label_80 = dat_train$label.1
idx80 = (1:length(label_80))[label_80==2]
boot80 = sample(idx80,sum(label_80!=2)/2-sum(label_80==2),replace = T)
dat_train_80 = rbind(dat_train,dat_train[boot80,])
clf80 = glmnet(data.matrix(dat_train_80[,-ncol(dat_train)]),dat_train_80[,ncol(dat_train)]==2
,family="binomial",alpha = 0,lambda=1.4)
# ridge lambda = 1.4
set.seed(3701)
label_90 = dat_train$label.1
idx90 = (1:length(label_90))[label_90==3]
boot90 = sample(idx90,sum(label_90!=3)/2-sum(label_90==3),replace = T)
dat_train_90 = rbind(dat_train,dat_train[boot90,])
clf90 = glmnet(data.matrix(dat_train_90[,-ncol(dat_train)]),dat_train_90[,ncol(dat_train)]==3
,family="binomial",alpha = 0,lambda=1.4)
# 00s Classifier
err_cal <- function(pred,k){
pred = sapply(pred, ch2int)
mean((pred!=(dat_train[idx==k,ncol(dat_train)]==4)))
}
err.tmp = matrix(rep(0,5*length(lam)),nrow=5)
for (k in 1:5) {
# Bootstrap
set.seed(k)
dat_train.tmp = dat_train[idx!=k,]
label_00 = dat_train.tmp$label.1
idx00 = (1:length(label_00))[label_00==4]
boot00 = sample(idx00,sum(label_00!=4)/2-sum(label_00==4),replace = T)
dat_train_00 = rbind(dat_train.tmp,dat_train.tmp[boot00,])
# Model Estimation
mr.tmp = glmnet(data.matrix(dat_train_00[,-ncol(dat_train)]),dat_train_00[,ncol(dat_train)]==4
,family="binomial",alpha = 0,lambda = lam)
pre.tmp = predict(mr.tmp,data.matrix(dat_train[idx==k,-ncol(dat_train)]),type="class")
err.tmp[k,] = apply(pre.tmp,2,err_cal,k=k)
}
ch2int <- function(ch){
if (ch == 'FALSE'){
return(0)
} else {
return(1)
}
}
# 00s Classifier
err_cal <- function(pred,k){
pred = sapply(pred, ch2int)
mean((pred!=(dat_train[idx==k,ncol(dat_train)]==4)))
}
err.tmp = matrix(rep(0,5*length(lam)),nrow=5)
for (k in 1:5) {
# Bootstrap
set.seed(k)
dat_train.tmp = dat_train[idx!=k,]
label_00 = dat_train.tmp$label.1
idx00 = (1:length(label_00))[label_00==4]
boot00 = sample(idx00,sum(label_00!=4)/2-sum(label_00==4),replace = T)
dat_train_00 = rbind(dat_train.tmp,dat_train.tmp[boot00,])
# Model Estimation
mr.tmp = glmnet(data.matrix(dat_train_00[,-ncol(dat_train)]),dat_train_00[,ncol(dat_train)]==4
,family="binomial",alpha = 0,lambda = lam)
pre.tmp = predict(mr.tmp,data.matrix(dat_train[idx==k,-ncol(dat_train)]),type="class")
err.tmp[k,] = apply(pre.tmp,2,err_cal,k=k)
}
plot(rev(lam),colMeans(err.tmp),"l",xlab = "lambda",ylab = "error rate")
label_00 = dat_train$label.1
idx00 = (1:length(label_00))[label_00==4]
boot00 = sample(idx00,sum(label_00!=4)/2-sum(label_00==4),replace = T)
dat_train_00 = rbind(dat_train,dat_train[boot00,])
clf00 = glmnet(data.matrix(dat_train_00[,-ncol(dat_train)]),dat_train_00[,ncol(dat_train)]==4
,family="binomial",alpha = 0,lambda=1.8)
# Maybe Counting on Genre
# first try it on Alternative
err_cal <- function(pred,k){
pred = sapply(pred, ch2int)
mean((pred!=(dat_train[idx==k,ncol(dat_train)]==5)))
}
err.tmp = matrix(rep(0,5*length(lam)),nrow=5)
for (k in 1:5) {
# Bootstrap
set.seed(k)
dat_train.tmp = dat_train[idx!=k,]
label_10 = dat_train.tmp$label.1
idx10 = (1:length(label_10))[label_10==5]
boot10 = sample(idx10,sum(label_10!=5)/2-sum(label_10==5),replace = T)
dat_train_10 = rbind(dat_train.tmp,dat_train.tmp[boot10,])
# Model Estimation
mr.tmp = glmnet(data.matrix(dat_train_10[,-ncol(dat_train)]),dat_train_10[,ncol(dat_train)]==5
,family="binomial",alpha = 0,lambda = lam)
pre.tmp = predict(mr.tmp,data.matrix(dat_train[idx==k,-ncol(dat_train)]),type="class")
err.tmp[k,] = apply(pre.tmp,2,err_cal,k=k)
}
plot(rev(lam),colMeans(err.tmp),"l",xlab = "lambda",ylab = "error rate")
# ridge lambda = .48
set.seed(3701)
label_10 = dat_train$label.1
idx10 = (1:length(label_10))[label_10==5]
boot10 = sample(idx10,sum(label_10!=5)/2-sum(label_10==5),replace = T)
dat_train_10 = rbind(dat_train,dat_train[boot10,])
clf10 = glmnet(data.matrix(dat_train_10[,-ncol(dat_train)]),dat_train_10[,ncol(dat_train)]==5
,family="binomial",alpha = 0,lambda=.48)
?predict.glmnet
pre.res = predict(m1,data.matrix(dat_test[,-ncol(dat_test)]),type = "response")
pre.res = predict(clf10,data.matrix(dat_test[,-ncol(dat_test)]),type = "response")
pre.res
pred=  pre.res
pred = sapply(pred, ch2int)
mean((pred!=(dat_test[,ncol(dat_train_10)]==5)))
pred
pre.res = predict(clf10,data.matrix(dat_test[,-ncol(dat_test)]),type = "class")
pred=  pre.res
pred
?argmax
?amax
?max
predict_mul <- function(X){
pre60 = predict(clf60,data.matrix(X),type="response")
pre70 = predict(clf70,data.matrix(X),type="response")
pre80 = predict(clf80,data.matrix(X),type="response")
pre90 = predict(clf90,data.matrix(X),type="response")
pre00 = predict(clf00,data.matrix(X),type="response")
pre10 = predict(clf10,data.matrix(X),type="response")
pre = cbind(pre60,pre70,pre80,pre90,pre00,pre10)
class = apply(pre,1,which.max)-1
return(class)
}
pre = predict_mul(dat_test[,-ncol(dat_test)])
head(pre)
mean(pre!=dat_test[,ncol(dat_test)])
